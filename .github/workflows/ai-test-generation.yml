name: AI Test Generation
on:
  push:
    branches: [ main ]
  issues:
    types: [labeled, opened]
  workflow_dispatch:
    inputs:
      issue_title:
        description: 'Issue title for test generation'
        required: false
        default: 'Manual test generation'
      issue_body:
        description: 'Issue description'
        required: false
        default: 'Generate unit tests manually'

jobs:
  generate-tests:
    if: ${{ github.event_name == 'workflow_dispatch' || (github.event_name == 'issues' && contains(github.event.issue.labels.*.name, 'ai-test-generation')) || github.event_name == 'push' }}
    runs-on: ubuntu-latest
    permissions:
      contents: write
      pull-requests: write
      issues: write
      pages: write
      id-token: write
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y gcc build-essential lcov
          git clone https://github.com/ThrowTheSwitch/Unity.git unity
          
      - name: Install Python dependencies
        run: |
          pip install google-generativeai python-dotenv
          
      - name: Create test directory
        run: |
          mkdir -p tests/generated
          
      - name: Generate tests with AI
        env:
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          ISSUE_TITLE: ${{ github.event.issue.title || github.event.inputs.issue_title || 'Manual test generation' }}
          ISSUE_BODY: ${{ github.event.issue.body || github.event.inputs.issue_body || 'Generate unit tests manually' }}
        run: |
          python scripts/ai_test_generator.py
          
      - name: Verify generated tests
        run: |
          echo "Generated tests:"
          ls -la tests/generated/
          if ls tests/generated/*_test.c 1> /dev/null 2>&1; then
            echo "Test files created successfully"
            for file in tests/generated/*_test.c; do
              echo "=== $file ==="
              head -10 "$file"
              echo "..."
            done
          else
            echo "No test files generated"
            exit 1
          fi
          
      - name: Commit generated tests
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add tests/generated/
          if [ "${{ github.event_name }}" == "issues" ]; then
            commit_msg="Add AI-generated test cases for issue #${{ github.event.issue.number }}"
          else
            commit_msg="Add AI-generated test cases (automated on push)"
          fi
          git commit -m "$commit_msg" || echo "No changes to commit"
          git push origin HEAD:${{ github.ref }} || echo "No changes to push"
          
      - name: Build and run tests
        run: |
          rm -rf build  # Clean previous build to avoid CMake cache conflicts
          mkdir -p build
          cd build
          # Build with coverage flags
          cmake -DCMAKE_C_FLAGS="--coverage" -DCMAKE_EXE_LINKER_FLAGS="--coverage" ..
          make
          
      - name: Run tests and capture output
        continue-on-error: true
        run: |
          output_file="test_output.txt"
          echo "Test Results:" > $output_file
          cd build
          overall_exit_code=0
          
          # Run all generated test executables
          for exe in *_test; do
            if [ -x "$exe" ]; then
              echo "Running $exe" >> ../$output_file
              ./$exe >> ../$output_file 2>&1
              test_exit_code=$?
              if [ $test_exit_code -ne 0 ]; then
                echo "Test $exe failed with exit code $test_exit_code" >> ../$output_file
                overall_exit_code=$test_exit_code
              fi
              echo "" >> ../$output_file
            fi
          done
          
          # Run manual test
          echo "Running manual test_temperature_sensor" >> ../$output_file
          ./test_temperature_sensor >> ../$output_file 2>&1
          manual_exit_code=$?
          if [ $manual_exit_code -ne 0 ]; then
            echo "Manual test failed with exit code $manual_exit_code" >> ../$output_file
            overall_exit_code=$manual_exit_code
          fi
          
          echo "Overall test run completed with exit code: $overall_exit_code" >> ../$output_file
          
          # Generate coverage report
          echo "Generating coverage report..." >> ../$output_file
          lcov --capture --directory . --output-file coverage.info >> ../$output_file 2>&1
          lcov --remove coverage.info '/usr/*' '*/unity/*' '*/test/*' --output-file coverage.info >> ../$output_file 2>&1
          genhtml coverage.info --output-directory ../coverage-report >> ../$output_file 2>&1
          
          # Always exit 0 to not fail the workflow
          exit 0
          
      - name: Display test results
        if: always()
        run: |
          echo "=== TEST RESULTS SUMMARY ==="
          if [ -f test_output.txt ]; then
            cat test_output.txt
          else
            echo "No test results file found"
          fi
          echo "=== END TEST RESULTS ==="
          
      - name: Upload test results
        if: always()
        run: |
          echo "Checking for test_output.txt..."
          ls -la test_output.txt || echo "test_output.txt not found"
          if [ -f test_output.txt ]; then
            echo "Test results file exists, uploading..."
          else
            echo "Creating empty test results file..."
            echo "No test results available - workflow may have failed early" > test_output.txt
          fi
          
      - name: Upload test results artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ github.run_id }}
          path: test_output.txt
          
      - name: Upload coverage report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report-${{ github.run_id }}
          path: coverage-report/
          
      - name: Comment on issue and remove label
        if: github.event_name == 'issues'
        run: |
          # Comment on the issue with test results
          gh issue comment ${{ github.event.issue.number }} --body-file test_output.txt
          # Remove the trigger label
          gh issue edit ${{ github.event.issue.number }} --remove-label ai-test-generation
          
      - name: Setup Pages
        if: github.ref == 'refs/heads/main'
        uses: actions/configure-pages@v5
        
      - name: Deploy coverage to GitHub Pages
        if: github.ref == 'refs/heads/main'
        uses: actions/deploy-pages@v4
        with:
          folder: coverage-report